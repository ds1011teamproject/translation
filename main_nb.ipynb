{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Main\n",
    "\n",
    "### First, let's import the libraries and configure logger. \n",
    "It will print lists of implemented models and data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import basic_conf as conf\n",
    "from libs import ModelManager as mm\n",
    "from config.constants import HyperParamKey, PathKey\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-11-04 16:31:24] [INFO] Initializing Model Manager, version 0.4.0 ...\n",
      "[2018-11-04 16:31:24] [INFO] \n",
      "=== Models Available ===\n",
      "BagOfWords\n",
      "========================\n",
      "[2018-11-04 16:31:24] [INFO] \n",
      "=== Loaders Available ===\n",
      "IMDB\n",
      "IWSLT\n",
      "========================\n",
      "[2018-11-04 16:31:24] [INFO] \n",
      "*********** Model Manager Details ***********\n",
      "-- self.hparams.num_epochs = 1\n",
      "-- self.hparams.lr = 0.01\n",
      "-- self.hparams.train_plus_val_size = 25000\n",
      "-- self.hparams.test_size = 25000\n",
      "-- self.hparams.val_size = 5000\n",
      "-- self.hparams.voc_size = 100000\n",
      "-- self.hparams.train_loop_check_freq = 100\n",
      "-- self.hparams.embedding_dim = 50\n",
      "-- self.hparams.batch_size = 32\n",
      "-- self.hparams.ngram_size = 2\n",
      "-- self.hparams.remove_punc = True\n",
      "-- self.hparams.check_early_stop = True\n",
      "-- self.hparams.es_look_back = 5\n",
      "-- self.hparams.es_req_prog = 0.01\n",
      "-- self.hparams.optim_enc = <class 'torch.optim.adam.Adam'>\n",
      "-- self.hparams.optim_dec = <class 'torch.optim.adam.Adam'>\n",
      "-- self.hparams.scheduler = <class 'torch.optim.lr_scheduler.ExponentialLR'>\n",
      "-- self.hparams.scheduler_gamma = 0.95\n",
      "-- self.hparams.criterion = <class 'torch.nn.modules.loss.CrossEntropyLoss'>\n",
      "-- self.cparams.save_best_model = True\n",
      "-- self.cparams.save_each_epoch = True\n",
      "-- self.cparams.data_path = /Users/xliu/Downloads/iwslt-vi-en/\n",
      "-- self.cparams.input_lang = vi\n",
      "-- self.cparams.output_lang = en\n",
      "-- self.cparams.model_saves = model_saves/\n",
      "-- self.lparams = None\n",
      "-- self.model = None\n",
      "-- self.dataloader = None\n",
      "-- self.results = []\n",
      "-- self.mode = notebook\n",
      "-- self.tqdm = <function tqdm_notebook at 0x12270c6a8>\n",
      "************ End of Model Manager Details ************\n"
     ]
    }
   ],
   "source": [
    "conf.init_logger(logging.DEBUG)\n",
    "logger = logging.getLogger('__main__')\n",
    "config_update = {'data_path': '/Users/xliu/Downloads/iwslt-vi-en/',\n",
    "                 PathKey.INPUT_LANG: 'vi'}\n",
    "mgr = mm.ModelManager(mode='notebook', control_overrides=config_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's load the data for translation task: IWSLT\n",
    "\n",
    "This might take a few minutes if it needs to generate the vocabulary, instead of load from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-11-04 16:31:27] [INFO] Loading data using IWSLT ...\n",
      "[2018-11-04 16:31:27] [INFO] Get source language datum list...\n",
      "[2018-11-04 16:31:28] [INFO] Get target language datum list...\n",
      "[2018-11-04 16:34:54] [INFO] Generated token2id, id2token for both src/target languages!\n",
      "[2018-11-04 16:34:54] [INFO] Convert token to index for source language ...\n",
      "[2018-11-04 16:34:56] [INFO] Convert token to index for target language ...\n",
      "[2018-11-04 16:34:57] [INFO] Datum list loaded for both src/target languages!\n"
     ]
    }
   ],
   "source": [
    "mgr.load_data(mm.loaderRegister.IWSLT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the actual vocabulary size returned by the data loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'act_vocab_size': {'source': 41962, 'target': 54117}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mgr.lparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first 5 samples in the train set:\n",
    "- tokens \n",
    "- token_indices\n",
    "\n",
    "Notice that there will be a EOS_IDX (1) added to the end of each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['khoa_học', 'đằng_sau', 'một', 'tiêu_đề', 'về', 'khí_hậu']\n",
      "[192, 1297, 8, 3224, 31, 849, 1] \n",
      "\n",
      "['trong', '4', 'phút', ',', 'chuyên_gia', 'hoá_học', 'khí_quyển', 'Rachel', 'Pike', 'giới_thiệu', 'sơ_lược', 'về', 'những', 'nỗ_lực', 'khoa_học', 'miệt_mài', 'đằng_sau', 'những', 'tiêu_đề', 'táo_bạo', 'về', 'biến_đổi', 'khí_hậu', ',', 'cùng', 'với', 'đoàn', 'nghiên_cứu', 'của', 'mình', '-', '-', 'hàng', 'ngàn', 'người', 'đã', 'cống_hiến', 'cho', 'dự_án', 'này', '-', '-', 'một', 'chuyến', 'bay', 'mạo_hiểm', 'qua', 'rừng_già', 'để', 'tìm_kiếm', 'thông_tin', 'về', 'một', 'phân_tử', 'then_chốt', '.']\n",
      "[15, 413, 383, 3, 882, 1065, 2008, 9396, 16190, 743, 9397, 31, 9, 1022, 192, 7376, 1297, 9, 3224, 2668, 31, 706, 849, 3, 149, 25, 3036, 156, 10, 73, 22, 22, 170, 675, 19, 17, 3109, 27, 318, 21, 22, 22, 8, 610, 465, 1686, 134, 10017, 29, 467, 222, 31, 8, 633, 3931, 4, 1] \n",
      "\n",
      "['tôi', 'muốn', 'cho', 'các', 'bạn', 'biết', 'về', 'sự', 'to_lớn', 'của', 'những', 'nỗ_lực', 'khoa_học', 'đã', 'góp_phần', 'làm_nên', 'các', 'dòng', 'tít', 'bạn', 'thường', 'thấy', 'trên', 'báo', '.']\n",
      "[7, 71, 27, 16, 11, 62, 31, 38, 960, 10, 9, 1022, 192, 17, 3000, 1830, 16, 730, 4750, 11, 253, 57, 55, 659, 4, 1] \n",
      "\n",
      "['có', 'những', 'dòng', 'trông', 'như', 'thế_này', 'khi', 'bàn', 'về', 'biến_đổi', 'khí_hậu', ',', 'và', 'như', 'thế_này', 'khi', 'nói', 'về', 'chất_lượng', 'không_khí', 'hay', 'khói', 'bụi', '.']\n",
      "[13, 9, 730, 357, 51, 380, 39, 676, 31, 706, 849, 3, 5, 51, 380, 39, 48, 31, 1068, 955, 80, 2838, 2396, 4, 1] \n",
      "\n",
      "['cả', 'hai', 'đều', 'là', 'một', 'nhánh', 'của', 'cùng', 'một', 'lĩnh_vực', 'trong', 'ngành', 'khoa_học', 'khí_quyển', '.']\n",
      "[107, 118, 117, 6, 8, 3533, 10, 149, 8, 642, 15, 425, 192, 2008, 4, 1] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(mgr.dataloader.data['source'][0][i].tokens)\n",
    "    print(mgr.dataloader.data['source'][0][i].token_indices, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try load the indexers from file (Double-check the vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-11-04 16:35:39] [INFO] Loading data using IWSLT ...\n",
      "[2018-11-04 16:35:40] [INFO] Get source language datum list...\n",
      "[2018-11-04 16:35:41] [INFO] Get target language datum list...\n",
      "[2018-11-04 16:35:42] [INFO] Vocabulary found and loaded! (token2id, id2token, vocabs)\n",
      "[2018-11-04 16:35:42] [INFO] Convert token to index for source language ...\n",
      "[2018-11-04 16:35:43] [INFO] Convert token to index for target language ...\n",
      "[2018-11-04 16:35:44] [INFO] Datum list loaded for both src/target languages!\n"
     ]
    }
   ],
   "source": [
    "mgr.load_data(mm.loaderRegister.IWSLT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['khoa_học', 'đằng_sau', 'một', 'tiêu_đề', 'về', 'khí_hậu']\n",
      "[192, 1297, 8, 3224, 31, 849, 1] \n",
      "\n",
      "['trong', '4', 'phút', ',', 'chuyên_gia', 'hoá_học', 'khí_quyển', 'Rachel', 'Pike', 'giới_thiệu', 'sơ_lược', 'về', 'những', 'nỗ_lực', 'khoa_học', 'miệt_mài', 'đằng_sau', 'những', 'tiêu_đề', 'táo_bạo', 'về', 'biến_đổi', 'khí_hậu', ',', 'cùng', 'với', 'đoàn', 'nghiên_cứu', 'của', 'mình', '-', '-', 'hàng', 'ngàn', 'người', 'đã', 'cống_hiến', 'cho', 'dự_án', 'này', '-', '-', 'một', 'chuyến', 'bay', 'mạo_hiểm', 'qua', 'rừng_già', 'để', 'tìm_kiếm', 'thông_tin', 'về', 'một', 'phân_tử', 'then_chốt', '.']\n",
      "[15, 413, 383, 3, 882, 1065, 2008, 9396, 16190, 743, 9397, 31, 9, 1022, 192, 7376, 1297, 9, 3224, 2668, 31, 706, 849, 3, 149, 25, 3036, 156, 10, 73, 22, 22, 170, 675, 19, 17, 3109, 27, 318, 21, 22, 22, 8, 610, 465, 1686, 134, 10017, 29, 467, 222, 31, 8, 633, 3931, 4, 1] \n",
      "\n",
      "['tôi', 'muốn', 'cho', 'các', 'bạn', 'biết', 'về', 'sự', 'to_lớn', 'của', 'những', 'nỗ_lực', 'khoa_học', 'đã', 'góp_phần', 'làm_nên', 'các', 'dòng', 'tít', 'bạn', 'thường', 'thấy', 'trên', 'báo', '.']\n",
      "[7, 71, 27, 16, 11, 62, 31, 38, 960, 10, 9, 1022, 192, 17, 3000, 1830, 16, 730, 4750, 11, 253, 57, 55, 659, 4, 1] \n",
      "\n",
      "['có', 'những', 'dòng', 'trông', 'như', 'thế_này', 'khi', 'bàn', 'về', 'biến_đổi', 'khí_hậu', ',', 'và', 'như', 'thế_này', 'khi', 'nói', 'về', 'chất_lượng', 'không_khí', 'hay', 'khói', 'bụi', '.']\n",
      "[13, 9, 730, 357, 51, 380, 39, 676, 31, 706, 849, 3, 5, 51, 380, 39, 48, 31, 1068, 955, 80, 2838, 2396, 4, 1] \n",
      "\n",
      "['cả', 'hai', 'đều', 'là', 'một', 'nhánh', 'của', 'cùng', 'một', 'lĩnh_vực', 'trong', 'ngành', 'khoa_học', 'khí_quyển', '.']\n",
      "[107, 118, 117, 6, 8, 3533, 10, 149, 8, 642, 15, 425, 192, 2008, 4, 1] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(mgr.dataloader.data['source'][0][i].tokens)\n",
    "    print(mgr.dataloader.data['source'][0][i].token_indices, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
