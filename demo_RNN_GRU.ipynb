{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN-Encoder-Decoder (GRU) Demo\n",
    "\n",
    "### First, let's import the libraries and configure logger. \n",
    "It will print lists of implemented models and data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import basic_conf as conf\n",
    "from libs import ModelManager as mm\n",
    "from config.constants import HyperParamKey, PathKey, ControlKey\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf.init_logger(logging.INFO)\n",
    "logger = logging.getLogger('__main__')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Change the DATA_PATH in config dict to your data path:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_new = {\n",
    "    PathKey.DATA_PATH: '/Users/xliu/Downloads/',\n",
    "    PathKey.INPUT_LANG: 'zh',\n",
    "    PathKey.OUTPUT_LANG: 'en'\n",
    "}\n",
    "\n",
    "hparam_new = {\n",
    "    HyperParamKey.EMBEDDING_DIM: 200,\n",
    "    HyperParamKey.ENC_LR: 0.005,\n",
    "    HyperParamKey.DEC_LR: 0.005,\n",
    "    HyperParamKey.BATCH_SIZE: 128,\n",
    "    HyperParamKey.TRAIN_LOOP_EVAL_FREQ: 10,\n",
    "    HyperParamKey.CHECK_EARLY_STOP: True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-11-08 22:42:15] [INFO] Initializing Model Manager, version 0.6.0 ...\n",
      "[2018-11-08 22:42:15] [INFO] \n",
      "=== Models Available ===\n",
      "RNN_GRU\n",
      "========================\n",
      "[2018-11-08 22:42:15] [INFO] \n",
      "=== Loaders Available ===\n",
      "IWSLT\n",
      "========================\n",
      "[2018-11-08 22:42:15] [INFO] \n",
      "*********** Model Manager Details ***********\n",
      "-- self.hparams.voc_size = 100000\n",
      "-- self.hparams.embedding_dim = 200\n",
      "-- self.hparams.hidden_size = 100\n",
      "-- self.hparams.enc_layers = 1\n",
      "-- self.hparams.enc_directions = 1\n",
      "-- self.hparams.dec_layers = 1\n",
      "-- self.hparams.dec_directions = 1\n",
      "-- self.hparams.teacher_forching_ratio = 0.5\n",
      "-- self.hparams.num_epochs = 1\n",
      "-- self.hparams.enc_lr = 0.005\n",
      "-- self.hparams.dec_lr = 0.005\n",
      "-- self.hparams.batch_size = 128\n",
      "-- self.hparams.train_loop_check_freq = 10\n",
      "-- self.hparams.check_early_stop = True\n",
      "-- self.hparams.es_look_back = 5\n",
      "-- self.hparams.es_req_prog = 0.01\n",
      "-- self.hparams.optim_method = <class 'torch.optim.adam.Adam'>\n",
      "-- self.hparams.scheduler = <class 'torch.optim.lr_scheduler.ExponentialLR'>\n",
      "-- self.hparams.scheduler_gamma = 0.95\n",
      "-- self.hparams.criterion = <class 'torch.nn.modules.loss.CrossEntropyLoss'>\n",
      "-- self.cparams.save_best_model = True\n",
      "-- self.cparams.save_each_epoch = True\n",
      "-- self.cparams.input_lang = zh\n",
      "-- self.cparams.data_path = /Users/xliu/Downloads/\n",
      "-- self.cparams.output_lang = en\n",
      "-- self.cparams.model_saves = model_saves/\n",
      "-- self.lparams = None\n",
      "-- self.model = None\n",
      "-- self.dataloader = None\n",
      "-- self.results = []\n",
      "-- self.mode = notebook\n",
      "-- self.tqdm = <function tqdm_notebook at 0x1250b80d0>\n",
      "************ End of Model Manager Details ************\n"
     ]
    }
   ],
   "source": [
    "mgr = mm.ModelManager(hparams=hparam_new, \n",
    "                      control_overrides=config_new, mode='notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-11-08 22:42:20] [INFO] Loading data using IWSLT ...\n",
      "[2018-11-08 22:42:20] [INFO] Get source language datum list...\n",
      "[2018-11-08 22:42:24] [INFO] Get target language datum list...\n",
      "[2018-11-08 22:42:26] [INFO] Vocabulary found and loaded! (token2id, id2token, vocabs)\n",
      "[2018-11-08 22:42:26] [INFO] Convert token to index for source language ...\n",
      "[2018-11-08 22:42:28] [INFO] Convert token to index for target language ...\n",
      "[2018-11-08 22:42:29] [INFO] Datum list loaded for both src/target languages!\n",
      "[2018-11-08 22:42:29] [INFO] Loading raw data into the DataLoaders ...\n"
     ]
    }
   ],
   "source": [
    "mgr.load_data(mm.loaderRegister.IWSLT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init a model RNN_GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-11-08 22:43:58] [INFO] \n",
      "*********** Model: grutrial Details ***********\n",
      "-- self.label = grutrial\n",
      "-- self.hparams.voc_size = 100000\n",
      "-- self.hparams.embedding_dim = 200\n",
      "-- self.hparams.hidden_size = 100\n",
      "-- self.hparams.enc_layers = 1\n",
      "-- self.hparams.enc_directions = 1\n",
      "-- self.hparams.dec_layers = 1\n",
      "-- self.hparams.dec_directions = 1\n",
      "-- self.hparams.teacher_forching_ratio = 0.5\n",
      "-- self.hparams.num_epochs = 1\n",
      "-- self.hparams.enc_lr = 0.005\n",
      "-- self.hparams.dec_lr = 0.005\n",
      "-- self.hparams.batch_size = 128\n",
      "-- self.hparams.train_loop_check_freq = 10\n",
      "-- self.hparams.check_early_stop = True\n",
      "-- self.hparams.es_look_back = 5\n",
      "-- self.hparams.es_req_prog = 0.01\n",
      "-- self.hparams.optim_method = <class 'torch.optim.adam.Adam'>\n",
      "-- self.hparams.scheduler = <class 'torch.optim.lr_scheduler.ExponentialLR'>\n",
      "-- self.hparams.scheduler_gamma = 0.95\n",
      "-- self.hparams.criterion = <class 'torch.nn.modules.loss.CrossEntropyLoss'>\n",
      "-- self.lparams.act_vocab_size = {'source': 89754, 'target': 69104}\n",
      "-- self.cparams.save_best_model = True\n",
      "-- self.cparams.save_each_epoch = True\n",
      "-- self.cparams.input_lang = zh\n",
      "-- self.cparams.data_path = /Users/xliu/Downloads/\n",
      "-- self.cparams.output_lang = en\n",
      "-- self.cparams.model_saves = model_saves/\n",
      "-- self.cparams.model_path = model_saves/grutrial/\n",
      "-- self.cur_epoch = 0\n",
      "-- self.output_dict.voc_size = 100000\n",
      "-- self.output_dict.embedding_dim = 200\n",
      "-- self.output_dict.hidden_size = 100\n",
      "-- self.output_dict.enc_layers = 1\n",
      "-- self.output_dict.enc_directions = 1\n",
      "-- self.output_dict.dec_layers = 1\n",
      "-- self.output_dict.dec_directions = 1\n",
      "-- self.output_dict.teacher_forching_ratio = 0.5\n",
      "-- self.output_dict.num_epochs = 1\n",
      "-- self.output_dict.enc_lr = 0.005\n",
      "-- self.output_dict.dec_lr = 0.005\n",
      "-- self.output_dict.batch_size = 128\n",
      "-- self.output_dict.train_loop_check_freq = 10\n",
      "-- self.output_dict.check_early_stop = True\n",
      "-- self.output_dict.es_look_back = 5\n",
      "-- self.output_dict.es_req_prog = 0.01\n",
      "-- self.output_dict.optim_method = <class 'torch.optim.adam.Adam'>\n",
      "-- self.output_dict.scheduler = <class 'torch.optim.lr_scheduler.ExponentialLR'>\n",
      "-- self.output_dict.scheduler_gamma = 0.95\n",
      "-- self.output_dict.criterion = <class 'torch.nn.modules.loss.CrossEntropyLoss'>\n",
      "-- self.output_dict.act_vocab_size = {'source': 89754, 'target': 69104}\n",
      "************ End of Model: grutrial Details ************\n",
      "[2018-11-08 22:43:58] [INFO] New Model initialized: /gru_trial, all model output files will be saved here: model_saves/grutrial/\n"
     ]
    }
   ],
   "source": [
    "mgr.new_model(mm.modelRegister.RNN_GRU,label='gru_trial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71aff9bb2f494c8c963a82d773f9ff98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-11-08 22:44:07] [INFO] stepped scheduler to epoch = 1\n",
      "[2018-11-08 22:44:55] [INFO] (epoch)1/1 (step)1/1668 (loss)11.177937507629395 (lr)e:0.005/d:0.005\n",
      "[2018-11-08 22:52:46] [INFO] (epoch)1/1 (step)11/1668 (loss)6.940803527832031 (lr)e:0.005/d:0.005\n"
     ]
    }
   ],
   "source": [
    "mgr.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
